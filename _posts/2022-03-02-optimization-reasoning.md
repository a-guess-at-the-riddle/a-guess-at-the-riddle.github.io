---
layout: post
title: Optimization and Reasoning
published: false
---

How is optimization related to reasoning?

After all Operations Research, an optimization-centric discipline, is often glossed as "mathematical decision making". So how is "decision making" related to "reasoning"? OR is sort of how post-WWII executives of large organizations such as the army make most of their most important quantitative decisions. Some of the most important algorithms used in AI originally come from this field (e.g. dynamic programming; also some would assoc. monte carlo methods with OR).

As a side note, my largest value-to-effort ratio trick when doing any speculation is using etymology and lexical knowledge to spontaneously associate word senses with each other and with their different etymological meanings through time. This basically assumes that there is a kind of latent knowledge/wisdom in the lexicon that can be mined by analyzing connotations that are not apparent at first glance to you (although they might be to people like Noah Webster, Peter Roget or those individuals who first coined new words by analogy to an old word). That is to say that most of our lexical knowledge (synonymy ...etc) is only subconsciously understood and not obvious to our normal everyday linguistic thinking. This is especially true in our modern day era where people don't put as much emphasis in education on being able to define the words you use. In other words have you ever realized that two words basically mean the same thing, but if you were asked prior (without much time to think) you would have guessed they were quite different? That is a very wordy way of saying if you don't have perfect linguistic ability, using a Thesaurus can improve not only your writing but your thinking too.

So in the example of optimization vs reasoning my thinking went like this:

A distinction between word senses is often made between reasoning as a system/process and the not well-defined phrase "a reason" (sometimes just "reason"). We can make an analogous distinction between optimization (a class of methods/algorithms) and the word "goal".

So "optimization" is to "goal" as "reasoning" is to "a reason". That is to say both "goal" and "a reason" are the primitive "atoms" of those respective domains. So how should we define some of these terms?

Optimization can be defined as choosing inputs (control variables) so as to maximize/minimize outputs. Said another way it is a method/process pertaining to navigating an abstract space (objective function) so as to get as close as possible to the goal state while satisfying certain constraints (constraints are not approximate you either meet them or not). The objective function encodes the notion of a metric designating the distance from the end state (so is approximately optimized. This is in contrast with a search algorithm which has no notion of closeness but rather can only succeed completely or fail completely (at least from what I can gloss after reading very little about it).

So what is meant by "a reason"? Well most people would say that it means an explanation or a cause. Here is an interesting historical fact from Wikipedia:
Aitia (Greek: αἰτία), the word that Aristotle used to refer to the causal explanation, has, in philosophical traditional, been translated as "cause." This peculiar, specialized, technical, usage of the word "cause" is not that of everyday English language. Rather, the translation of Aristotle's αἰτία that is nearest to current ordinary language is "explanation". 

This because in history the meaning of cause was reduced from an answer to all (or most?) meanings of why questions (all 4 of Aristotle's αἰτία) to just one, efficient cause/explanation. Francis Bacon writing in the time of Shakespeare was the one who strongly argued that natural science should ignore final and formal causes. But regardless teleological thinking (i.e., final cause) remained important to Biology until Darwin published his On the Origin of Species. Many people saw this as the death of final cause/teleology/finality. But actually to the present day the notion of "function" has remained very central to Biology. "Function" being related to ideas such as cause, purpose, and role.

Teleology/finality can be contrasted with mechanism. Or in the view of C. S. Peirce the difference between teleology and mechanism can is seen as analogous to the difference between his notions of type and token. That is mechanism is associated with the notion of a single trajectory/mechanism while finality is associated with a multiply realizable final state (i.e., approachable by many different trajectories/mechanisms that all converge on this set of final states). You can see some people like to associate this with the idea of a/an attractor/strange attractor from nonlinear dynamics. To Peirce these two types of change are always considered to be acting either simultaneously (duality) or together with a third type of change objective chance (uncaused/spontaneous change) as a triad.

So then "a reason" can be thought of as efficient cause (mechanistic cause) or final cause (i.e., goal/purpose). Also some people have used the phrase "a reason" like when they state that a certain event occured due to chance, luck or coincidence (e.g. "it was just a coincidence"). I think Peirce would argue that these are a kind of presuppositional duality similar to the concepts of generality and specificity (they imply each other/are defined relative to one another) and also that of type/token.

Also what is "the reason" we optimize and what is "the reason" we use/have reason? What would it mean for our reasoning itself to be optimum?


Now I wonder if this is somehow related to Peirce's classification of 3 types of inferences (i.e. abduction, deduction, induction). Their correspondence to the causes/explanations would be abduction/chance, deduction/efficient cause, and induction/final cause. Not sure what this implies...

Anyways we can say that optimization is a species of reason in that it is closely related to final cause and induction.

But how exactly is inductive inference related to optimization, final cause, finality?

I'm curious about this nineteenth-century thinker William Whewell who is most known today for his writing on the philosophy and history of science (History of the Inductive Sciences and The Philosophy of the Inductive Sciences). I'm pretty sure his writing influenced Peirce. Here is some text from the beginning of the Wikipedia page on his idea of convergence of in science called conscillence:

>In science and history, consilience (also convergence of evidence or concordance of evidence) is the principle that evidence from independent, unrelated sources can "converge" on strong conclusions. That is, when multiple sources of evidence are in agreement, the conclusion can be very strong even when none of the individual sources of evidence is significantly so on its own. Most established scientific knowledge is supported by a convergence of evidence: if not, the evidence is comparatively weak, and there will not likely be a strong scientific consensus.

The principle is based on the unity of knowledge; measuring the same result by several different methods should lead to the same answer.
(https://en.wikipedia.org/wiki/Consilience)


Future questions (how is opimization and inductive inference related to):

- causality/explanation in evolution?

- divergence and convergence in search algorithms (Kenneth Stanley) and bidirectional search?

- extrinsic purpose vs intrinic purpose

- definition of function as purpose vs mathematical function as table vs computational algorithm used to compute function

historical perspective = contextual/specific vs physics perspective = natural law/generality

Peirce law of mind

kierandkelly.com (course harmonic motion)

the incremental compression conjecture

How is rationality related to the even divisibility relation?

self-organization and distributed representations

ententional concepts:

aboutness
adaptation
consciousness
function
intentionality
life
meaning
normativity
symbols
purpose
teleology
thought









science vs engineering mirror descriptive vs prescriptive
i.e. engineering is about using work to create instruments that can acts as means to a goal















Peter  2:35 PM
Have you ever wondered how optimization and reasoning are related?

John Cerkan  2:51 PM
I'm not sure.  I guess reasoning leads to optimization.  But optimization can lead to less reasoning by skipping the reasoning step.

Peter  2:52 PM
How would optimization allow you to skip a step?
2:52
You mean like a shorter proof?
2:52
vs a longer proof
2:53
or argument

John Cerkan  2:53 PM
So if I do something a bunch of times, I tend to think about it less as I get used to it.  After awhile it's automatic.  At some point there's not much to optimize.

Peter  2:54 PM
I should say that I'm using the word reasoning in the very broad way that philosophers do when they talk of philosophical logic. For Peirce he classified most if not all reasoning into three kinds of inference abductive, deductive, and inductive.
2:58
Is there multiple senses to the word optimization? Like is optimization in the sense of an optimizing compiler the same meaning as   when used as in say finding the optimum logistic schedule.
3:01
I say so because your example of habit formation is something that runs and returns an output multiple times before it runs optimally and returns the same output. But in the example of say a mathematical optimization problem it is computed once (however efficiently) and return the optimum output. So I guess the difference is optimization of a process that is optimized by running multiple times vs optimization of a processes output. That is get as close as possible to the goal. (edited) 
3:01
Does that make sense?
3:02
Although I sometimes find it frustrating that you always seem to think of things differently than I do, I gotta say it is quite productive.

Peter  3:08 PM
I would call what you said habit formation or more generally self-organization. What would be a computer science or applied mathematics example of that kind of optimization ? We could call it process optimization (There is a Wikipedia page on that but not much info. I don't know if it is a well known term or what its formalized version is called).

Peter  3:14 PM
I guess it could be summed up as optimize the means vs optimize the ends.

John Cerkan  3:15 PM
Yes, habit formation is probably a kind of optimization.  Optimization is also sort of relative.  A program could be optimized for speed or memory use.

Peter  3:18 PM
Yes I understand. It makes sense that you approached it from the software engineering perspective (which focuses on efficiency). After all the majority of the popular programs are not batch programs but interactive programs. That is why I brought up the optimizing compiler (I was thinking of software), But I think that example of the compiler actually didn't fit in the process optimization category
3:18
Also the output of many programs are also programs and not data.
3:20
So as you say you might want to optimize the efficiency of that program in terms of memory or speed. But I was originally focused on mathematical optimization. As far as I know it doesn't get into such complex notions as we encounter in the software world. (You would think it should as it would be helpful)
3:23
Habit formation is an recursive process that takes as input sense data and outputs a process which takes in sense data which outputs a process ...etc, and approaches some attractor in the process/habit space. (edited) 
3:24
Or at least that is one formalization of it.

Peter  3:32 PM
Are you aware of any purely mathematical study of this? (its possible that it could exist in the more advanced mathematical optimization content)
Of course does it even belong to the domain of mathematics? (edited) 

Peter  3:45 PM
Perhaps I'm forgetting my computer science theory (the very little I know). I think that the distinction between process and data isn't important to a computer.
3:48
so functions are computable numbers
3:48
I'm clearly not educated enough on the matter to be speculating on it (edited) 

John Cerkan  3:50 PM
I feel like I have seen a textbook with optimization, but I'm not sure if that was an engineering book or what I'm almost remembering.

Peter  3:52 PM
Also in lambda calculus it is just opposite. Instead of everything being a computable number, everything is a function and some functions can be interpreted as numbers.
3:53
I find this whole topic very interesting
3:57
Like is there any difference between process thought of as dynamical and its input output relations thought of as static? This reminds me of some of Peirce's ideas about the complementarity (is that the right term?) of mechanism (algorithm?) and finality.
3:57
We have spoken about such things before.

Peter  4:07 PM
I wrote a short essay on this but now I need to rewrite it as I was thinking of optimization too narrowly.

Peter  4:13 PM
But I will just tell you the interesting lexical observation I made. When we say the phrase "a reason" we can either mean an argument/proof or a purpose/goal (or a coincidence/chance). This fits into my overall narrative so far.
4:13
"a reason this theorem is true" vs "a reason to run for office"
4:14
its like we can either refer to the past or the future

John Cerkan  4:17 PM
They seem very similar, but if i give it time, they seem very different.

Peter  4:18 PM
well it is just the final cause vs efficient cause thing again

Peter  4:24 PM
Why is a theorem true?
Because we established in the past that the propositions of the proof are actually true, the inference rules are valid, and the propositions of the proof follow from each other using the inference rules (of course there are assumed intermediate propositions that people will sometimes use)
Why does someone want to run for office?
Because they desire to change the future possible state of the world (become more rich, increase prosperity of their jurisdiction, ... etc.)
4:25
actual past vs possible future
4:28
but I do seem some problems with this that I will have to work out

Peter  4:36 PM
Here is a helpful distinction I have mentioned before. Many proofs through the theorem space (some kind of graph I guess...) will lead to the same theorem. So a theorem is like a goal and a proof is like a specific means (one among many) to a goal.

Peter  4:49 PM
I'm interested in how these ideas relate to self-organization and also this old idea called consilience.

John Cerkan  4:49 PM
It makes me wonder if an argument makes a theorem true.  If there are multiple arguments then one can't be given credit.  But an argument can be the reason someone believes a theorem.  The theorem was true anyway.

Peter  4:50 PM
Yes the word "truth" has multiple interpretations in even mathematics.
4:51
One more recent interpretation by the computer science (type theory) influenced people is true means you have a proof. Perhaps a Ramanujan like Platonist would way something like what you are saying. (edited) 
4:55
Also echoing the pragmatists a theorem once proven just becomes another stepping stone (instrument, means, etc...) for your future proofs. This mirrors how completed goal(s) become the perspectives from which we form our next goal(s). That is to say the distinction between means and ends depends on time.

Peter  5:08 PM
Now to make a speculative leap...
It is interesting to think about how habits are formed (sometimes even as an intentional goal, e.g. single digit multiplication) and then those habits become mechanisms from which we build our more complex compound habits (e.g., one step in solving a very simple algebraic equation).
Or we can more away from the pencil pusher example and talk about something like playing a musical instrument (e.g. a piano). First you makes the habitual connection between your hand configuration and the note/chord. Next you form habits relating to rhythms of single notes/chords. Then you habituate simple note sequences and simple chord progression/cadences. etc...
Eventually you start to generalize. For example you can play a I, IV, V chord progression in any major key. Later if you get to be as skilled as a professional musician, you start to be able to improvise certain motifs and themes.
When you are doing such an act as improvising a theme you have a high-level goal and with many possible paths to that goal. In this way working through a proof and performing a fugue are similar.
5:12
Also I am thinking of a mathematician performing deduction as partially spontaneous just like the decision to move between one chord and another is partially spontaneous and partially constrained.

Thinking more about the empirical sciences than mathematics (would this apply to math?), what about the fact that your beginning (starting point in a chain of reasoning) can be someone else's goal? Or even you have different incomplete arguments (chains of reasoning) that you have in your memory and you jump between them. Also multiple chains of reasoning (starting from the same point or not and in the mind of the same person or not) can lead to the same conclusion.
Funny enough there is a famous lyrics from a 90s alt rocks song Closing Time:
So, gather up your jackets, move it to the exits
I hope you have found a friend
Closing time, every new beginning
Comes from some other beginning's end, yeah
But those beginnings don't have to be the exact same beginnings (from a different argument or from a different mind).
So earlier I mentioned consilience here is the definition from Wikipedia:
In science and history, consilience (also convergence of evidence or concordance of evidence) is the principle that evidence from independent, unrelated sources can "converge" on strong conclusions. That is, when multiple sources of evidence are in agreement, the conclusion can be very strong even when none of the individual sources of evidence is significantly so on its own. Most established scientific knowledge is supported by a convergence of evidence: if not, the evidence is comparatively weak, and there will not likely be a strong scientific consensus.
The principle is based on the unity of knowledge; measuring the same result by several different methods should lead to the same answer.
And I saw this image (about bidirectional search) from the AGI lecture I posted for you to watch the other week: (edited)


5:33
The effectiveness of bidirectional search (and n-directional search???) depends on perspective (very "Copernican principle").

What happens when you generalize bidirectional search to a goal hierarchy or goal space?

5:34
I was thinking about this because that same lecturer is always talking about divergence and convergence.
5:36
One would infer from this line of thinking that in order to have consilience (and strong intelligence) one needs intelligences spread throughout some kind of abstract space. This would allow a kind of triangulation or mutual constraint that would reduce the search space and improve the efficiency of the computation. (edited) 


active media (energy necessary for "reward")?

According to Wikipedia, true consilience is about differenty modes of measurement pitted against one another (ala error detecting codes)

Whewell’s definition was that:[10]

The Consilience of Inductions takes place when an Induction, obtained from one class of facts, coincides with an Induction obtained from another different class. Thus Consilience is a test of the truth of the Theory in which it occurs.

More recent descriptions include:

"Where there is convergence of evidence, where the same explanation is implied, there is increased confidence in the explanation. Where there is divergence, then either the explanation is at fault or one or more of the sources of information is in error or requires reinterpretation."[11]

"Proof is derived through a convergence of evidence from numerous lines of inquiry--multiple, independent inductions, all of which point to an unmistakable conclusion."[6]
